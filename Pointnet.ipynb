{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c2f072-f4cd-4da4-acf8-f6168fe60fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for PointNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"fc3.weight\", \"fc3.bias\". \n\tUnexpected key(s) in state_dict: \"mlp1.weight\", \"mlp1.bias\", \"mlp2.weight\", \"mlp2.bias\", \"mlp3.weight\", \"mlp3.bias\". \n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([128, 256, 1]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([5, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     58\u001b[39m num_cls = ckpt[\u001b[33m'\u001b[39m\u001b[33mnum_classes\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     60\u001b[39m model = PointNet(num_classes=num_cls).to(DEVICE)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodel_state\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m model.eval()\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# LOAD RAW\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\anaconda\\Lib\\site-packages\\torch\\nn\\modules\\module.py:2593\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2585\u001b[39m         error_msgs.insert(\n\u001b[32m   2586\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2588\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2589\u001b[39m             ),\n\u001b[32m   2590\u001b[39m         )\n\u001b[32m   2592\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2594\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2595\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2596\u001b[39m         )\n\u001b[32m   2597\u001b[39m     )\n\u001b[32m   2598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for PointNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"fc3.weight\", \"fc3.bias\". \n\tUnexpected key(s) in state_dict: \"mlp1.weight\", \"mlp1.bias\", \"mlp2.weight\", \"mlp2.bias\", \"mlp3.weight\", \"mlp3.bias\". \n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([128, 256, 1]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([5, 128, 1]) from checkpoint, the shape in current model is torch.Size([128, 256]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([128])."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import laspy\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# CHANGE THESE PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"D:\\lidarrrrr\\anbu\\dl_models\\pointnet_best.pt\"\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000001.laz\"\n",
    "OUT_FILE   = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000001_PRED_PT.laz\"\n",
    "\n",
    "GT_FILE    = r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000001.laz\"   # for REAL accuracy\n",
    "\n",
    "NPTS = 4096\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Device:\",DEVICE)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self,num_classes=7):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(4,64,1)\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,256,1)\n",
    "        self.conv4 = nn.Conv1d(256,512,1)\n",
    "\n",
    "        self.fc1 = nn.Linear(512,256)\n",
    "        self.fc2 = nn.Linear(256,128)\n",
    "        self.fc3 = nn.Linear(128,num_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        x = torch.max(x,2)[0]\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x.unsqueeze(1).repeat(1,4096,1)\n",
    "# -----------------------------\n",
    "# LOAD MODEL (.pt)\n",
    "# -----------------------------\n",
    "ckpt = torch.load(MODEL_PATH,map_location=DEVICE)\n",
    "\n",
    "num_cls = ckpt['num_classes']\n",
    "\n",
    "model = PointNet(num_classes=num_cls).to(DEVICE)\n",
    "\n",
    "model.load_state_dict(ckpt['model_state'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD RAW\n",
    "# -----------------------------\n",
    "las = laspy.read(RAW_FILE)\n",
    "\n",
    "xyz = np.vstack([las.x,las.y,las.z]).T.astype(np.float32)\n",
    "intensity = np.array(las.intensity,dtype=np.float32)\n",
    "\n",
    "if intensity.max()>intensity.min():\n",
    "    intensity = (intensity-intensity.min())/(intensity.max()-intensity.min()+1e-6)\n",
    "\n",
    "feat = np.concatenate([xyz,intensity[:,None]],axis=1)\n",
    "\n",
    "# -----------------------------\n",
    "# BLOCKS\n",
    "# -----------------------------\n",
    "def make_blocks(feat,npts=4096):\n",
    "    idx = np.random.permutation(len(feat))\n",
    "    blocks=[]\n",
    "    for i in range(0,len(feat),npts):\n",
    "        b = idx[i:i+npts]\n",
    "        if len(b)<npts:\n",
    "            b = np.pad(b,(0,npts-len(b)),mode='wrap')\n",
    "        blocks.append(b)\n",
    "    return blocks\n",
    "\n",
    "blocks = make_blocks(feat,NPTS)\n",
    "\n",
    "pred_lbl = np.zeros(len(feat),dtype=np.int32)\n",
    "\n",
    "print(\"Predicting...\")\n",
    "\n",
    "for b in tqdm(blocks):\n",
    "\n",
    "    xb = feat[b].copy()\n",
    "\n",
    "    xb[:,0]-=xb[:,0].mean()\n",
    "    xb[:,1]-=xb[:,1].mean()\n",
    "    xb[:,2]-=xb[:,2].min()\n",
    "\n",
    "    xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(xt)\n",
    "        p = out.argmax(2).cpu().numpy()[0]\n",
    "\n",
    "    pred_lbl[b] = p\n",
    "\n",
    "# -----------------------------\n",
    "# SAVE PRED\n",
    "# -----------------------------\n",
    "out = laspy.LasData(header=las.header)\n",
    "out.points = las.points\n",
    "out.classification = pred_lbl.astype(np.uint8)\n",
    "out.write(OUT_FILE)\n",
    "\n",
    "print(\"Saved:\",OUT_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# REAL ACCURACY (GT vs PRED)\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "\n",
    "y_true = np.array(gt.classification)\n",
    "y_pred = pred_lbl\n",
    "\n",
    "mask = np.isin(y_true,[1,2,3,6])\n",
    "\n",
    "y_true = y_true[mask]\n",
    "y_pred = y_pred[mask]\n",
    "\n",
    "rep = classification_report(y_true,y_pred,labels=[1,2,3,6],output_dict=True,zero_division=0)\n",
    "cm  = confusion_matrix(y_true,y_pred,labels=[1,2,3,6])\n",
    "\n",
    "print(\"\\nREAL ACCURACY\\n\")\n",
    "\n",
    "for c in [2,3,6]:\n",
    "    acc = rep[str(c)]['recall']*100\n",
    "    print(f\"Class {c} Accuracy: {acc:.2f}%\")\n",
    "\n",
    "overall = np.trace(cm)/np.sum(cm)*100\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23976f4-2e64-4ecc-88ca-01a28d894890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['model_state', 'num_classes', 'class_weights'])\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(MODEL_PATH,map_location=\"cpu\")\n",
    "\n",
    "print(type(ckpt))\n",
    "print(ckpt.keys() if isinstance(ckpt,dict) else \"Not a dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3539a36-8271-4496-8ebc-cc8145f9c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp1.weight\n",
      "mlp1.bias\n",
      "mlp2.weight\n",
      "mlp2.bias\n",
      "mlp3.weight\n",
      "mlp3.bias\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "\n",
    "for k in ckpt['model_state'].keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96ff3dd-782f-4c9d-aeaa-5864f003fcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Checkpoint num_classes: 5\n",
      "✅ Loaded PointNet weights.\n",
      "Model expects input features C = 10\n",
      "Predicting blocks: 371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371/371 [00:05<00:00, 64.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000001_PRED_PT.laz\n",
      "\n",
      "REAL ACCURACY (PointNet)\n",
      "\n",
      "Class 2 Accuracy (Recall): 99.99%\n",
      "Class 3 Accuracy (Recall): 0.00%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 27.51%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# EDIT THESE PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"D:\\lidarrrrr\\anbu\\dl_models\\pointnet_best.pt\"   # your .pt\n",
    "GT_FILE    = r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000001.laz\"          # classified (ground truth)\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000001.laz\"         # will be created from GT if not exists\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000001_PRED_PT.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) MAKE RAW FROM GT (same points, perfect for real accuracy)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    os.makedirs(os.path.dirname(raw_path), exist_ok=True)\n",
    "    las = laspy.read(gt_path)\n",
    "    print(\"GT classes:\", np.unique(las.classification))\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) BUILD MODEL FROM CHECKPOINT SHAPES (NO GUESSING)\n",
    "# -----------------------------\n",
    "class PointNetFromCkpt(nn.Module):\n",
    "    def __init__(self, sd):\n",
    "        super().__init__()\n",
    "        # Conv1d weights are [out_channels, in_channels, 1]\n",
    "        def conv_from(key):\n",
    "            w = sd[key + \".weight\"]\n",
    "            out_ch, in_ch, k = w.shape\n",
    "            assert k == 1, f\"{key} kernel is not 1, got {k}\"\n",
    "            return nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=True)\n",
    "\n",
    "        self.mlp1 = conv_from(\"mlp1\")\n",
    "        self.mlp2 = conv_from(\"mlp2\")\n",
    "        self.mlp3 = conv_from(\"mlp3\")\n",
    "        self.fc1  = conv_from(\"fc1\")\n",
    "        self.fc2  = conv_from(\"fc2\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.mlp1(x))\n",
    "        x = F.relu(self.mlp2(x))\n",
    "        x = F.relu(self.mlp3(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)          # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1) # [B, N, num_classes]\n",
    "\n",
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "\n",
    "# Your checkpoint keys are: model_state, num_classes, class_weights\n",
    "sd = ckpt[\"model_state\"]\n",
    "num_classes = int(ckpt.get(\"num_classes\", sd[\"fc2.weight\"].shape[0]))\n",
    "print(\"Checkpoint num_classes:\", num_classes)\n",
    "\n",
    "model = PointNetFromCkpt(sd).to(DEVICE)\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(\"✅ Loaded PointNet weights.\")\n",
    "if missing:    print(\"Missing:\", missing)\n",
    "if unexpected: print(\"Unexpected:\", unexpected)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) FEATURES (match your training: XYZ + Intensity + returns)\n",
    "#    If your model was trained with a different C, we auto-pad/trim.\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    # base features\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    # pad with zeros\n",
    "    pad = np.zeros((X.shape[0], target_C - C), dtype=X.dtype)\n",
    "    return np.concatenate([X, pad], axis=1)\n",
    "\n",
    "# model input channels = mlp1 in_channels\n",
    "C_in = model.mlp1.in_channels\n",
    "print(\"Model expects input features C =\", C_in)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) PREDICT (block by block)\n",
    "# -----------------------------\n",
    "def make_blocks(n_points, npts=4096):\n",
    "    idx = np.arange(n_points)\n",
    "    np.random.shuffle(idx)\n",
    "    blocks = []\n",
    "    for i in range(0, n_points, npts):\n",
    "        b = idx[i:i+npts]\n",
    "        if len(b) < npts:\n",
    "            b = np.pad(b, (0, npts-len(b)), mode=\"wrap\")\n",
    "        blocks.append(b)\n",
    "    return blocks\n",
    "\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = build_features(raw)\n",
    "X_all = fit_C(X_all, C_in)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "blocks = make_blocks(N, NPTS)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "\n",
    "        # simple per-block normalization\n",
    "        xb[:, 0] -= xb[:, 0].mean()\n",
    "        xb[:, 1] -= xb[:, 1].mean()\n",
    "        xb[:, 2] -= xb[:, 2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)  # [1,NPTS,C]\n",
    "        logits = model(xt)                                         # [1,NPTS,num_classes]\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) REAL ACCURACY (GT vs PRED) — SAME POINTS = TRUE ACCURACY\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "# report only main classes (edit if you want more)\n",
    "labels = [1, 2, 3, 6]\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() > 0 else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet)\\n\")\n",
    "for c in [2, 3, 6]:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c636e380-9c45-4318-814d-861c07f819d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Checkpoint num_classes: 5\n",
      "✅ Loaded PointNet weights.\n",
      "Model expects input features C = 10\n",
      "Predicting blocks: 853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 853/853 [00:01<00:00, 517.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000002_PRED_PT.laz\n",
      "\n",
      "REAL ACCURACY (PointNet)\n",
      "\n",
      "Class 2 Accuracy (Recall): 99.99%\n",
      "Class 3 Accuracy (Recall): 0.01%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 28.87%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# EDIT THESE PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"D:\\lidarrrrr\\anbu\\dl_models\\pointnet_best.pt\"   # your .pt\n",
    "GT_FILE    = r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000002.laz\"          # classified (ground truth)\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000002.laz\"         # will be created from GT if not exists\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000002_PRED_PT.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) MAKE RAW FROM GT (same points, perfect for real accuracy)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    os.makedirs(os.path.dirname(raw_path), exist_ok=True)\n",
    "    las = laspy.read(gt_path)\n",
    "    print(\"GT classes:\", np.unique(las.classification))\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) BUILD MODEL FROM CHECKPOINT SHAPES (NO GUESSING)\n",
    "# -----------------------------\n",
    "class PointNetFromCkpt(nn.Module):\n",
    "    def __init__(self, sd):\n",
    "        super().__init__()\n",
    "        # Conv1d weights are [out_channels, in_channels, 1]\n",
    "        def conv_from(key):\n",
    "            w = sd[key + \".weight\"]\n",
    "            out_ch, in_ch, k = w.shape\n",
    "            assert k == 1, f\"{key} kernel is not 1, got {k}\"\n",
    "            return nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=True)\n",
    "\n",
    "        self.mlp1 = conv_from(\"mlp1\")\n",
    "        self.mlp2 = conv_from(\"mlp2\")\n",
    "        self.mlp3 = conv_from(\"mlp3\")\n",
    "        self.fc1  = conv_from(\"fc1\")\n",
    "        self.fc2  = conv_from(\"fc2\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.mlp1(x))\n",
    "        x = F.relu(self.mlp2(x))\n",
    "        x = F.relu(self.mlp3(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)          # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1) # [B, N, num_classes]\n",
    "\n",
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "\n",
    "# Your checkpoint keys are: model_state, num_classes, class_weights\n",
    "sd = ckpt[\"model_state\"]\n",
    "num_classes = int(ckpt.get(\"num_classes\", sd[\"fc2.weight\"].shape[0]))\n",
    "print(\"Checkpoint num_classes:\", num_classes)\n",
    "\n",
    "model = PointNetFromCkpt(sd).to(DEVICE)\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(\"✅ Loaded PointNet weights.\")\n",
    "if missing:    print(\"Missing:\", missing)\n",
    "if unexpected: print(\"Unexpected:\", unexpected)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) FEATURES (match your training: XYZ + Intensity + returns)\n",
    "#    If your model was trained with a different C, we auto-pad/trim.\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    # base features\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    # pad with zeros\n",
    "    pad = np.zeros((X.shape[0], target_C - C), dtype=X.dtype)\n",
    "    return np.concatenate([X, pad], axis=1)\n",
    "\n",
    "# model input channels = mlp1 in_channels\n",
    "C_in = model.mlp1.in_channels\n",
    "print(\"Model expects input features C =\", C_in)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) PREDICT (block by block)\n",
    "# -----------------------------\n",
    "def make_blocks(n_points, npts=4096):\n",
    "    idx = np.arange(n_points)\n",
    "    np.random.shuffle(idx)\n",
    "    blocks = []\n",
    "    for i in range(0, n_points, npts):\n",
    "        b = idx[i:i+npts]\n",
    "        if len(b) < npts:\n",
    "            b = np.pad(b, (0, npts-len(b)), mode=\"wrap\")\n",
    "        blocks.append(b)\n",
    "    return blocks\n",
    "\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = build_features(raw)\n",
    "X_all = fit_C(X_all, C_in)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "blocks = make_blocks(N, NPTS)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "\n",
    "        # simple per-block normalization\n",
    "        xb[:, 0] -= xb[:, 0].mean()\n",
    "        xb[:, 1] -= xb[:, 1].mean()\n",
    "        xb[:, 2] -= xb[:, 2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)  # [1,NPTS,C]\n",
    "        logits = model(xt)                                         # [1,NPTS,num_classes]\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) REAL ACCURACY (GT vs PRED) — SAME POINTS = TRUE ACCURACY\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "# report only main classes (edit if you want more)\n",
    "labels = [1, 2, 3, 6]\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() > 0 else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet)\\n\")\n",
    "for c in [2, 3, 6]:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4bd39b9-76b4-4000-ae38-b6f4d3fda87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Checkpoint num_classes: 5\n",
      "✅ Loaded PointNet weights.\n",
      "Model expects input features C = 10\n",
      "Predicting blocks: 552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 552/552 [00:01<00:00, 548.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000003_PRED_PT.laz\n",
      "\n",
      "REAL ACCURACY (PointNet)\n",
      "\n",
      "Class 2 Accuracy (Recall): 99.89%\n",
      "Class 3 Accuracy (Recall): 0.33%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 49.42%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# EDIT THESE PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"D:\\lidarrrrr\\anbu\\dl_models\\pointnet_best.pt\"   # your .pt\n",
    "GT_FILE    = r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000003.laz\"          # classified (ground truth)\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000003.laz\"         # will be created from GT if not exists\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000003_PRED_PT.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) MAKE RAW FROM GT (same points, perfect for real accuracy)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    os.makedirs(os.path.dirname(raw_path), exist_ok=True)\n",
    "    las = laspy.read(gt_path)\n",
    "    print(\"GT classes:\", np.unique(las.classification))\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) BUILD MODEL FROM CHECKPOINT SHAPES (NO GUESSING)\n",
    "# -----------------------------\n",
    "class PointNetFromCkpt(nn.Module):\n",
    "    def __init__(self, sd):\n",
    "        super().__init__()\n",
    "        # Conv1d weights are [out_channels, in_channels, 1]\n",
    "        def conv_from(key):\n",
    "            w = sd[key + \".weight\"]\n",
    "            out_ch, in_ch, k = w.shape\n",
    "            assert k == 1, f\"{key} kernel is not 1, got {k}\"\n",
    "            return nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=True)\n",
    "\n",
    "        self.mlp1 = conv_from(\"mlp1\")\n",
    "        self.mlp2 = conv_from(\"mlp2\")\n",
    "        self.mlp3 = conv_from(\"mlp3\")\n",
    "        self.fc1  = conv_from(\"fc1\")\n",
    "        self.fc2  = conv_from(\"fc2\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.mlp1(x))\n",
    "        x = F.relu(self.mlp2(x))\n",
    "        x = F.relu(self.mlp3(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)          # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1) # [B, N, num_classes]\n",
    "\n",
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "\n",
    "# Your checkpoint keys are: model_state, num_classes, class_weights\n",
    "sd = ckpt[\"model_state\"]\n",
    "num_classes = int(ckpt.get(\"num_classes\", sd[\"fc2.weight\"].shape[0]))\n",
    "print(\"Checkpoint num_classes:\", num_classes)\n",
    "\n",
    "model = PointNetFromCkpt(sd).to(DEVICE)\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(\"✅ Loaded PointNet weights.\")\n",
    "if missing:    print(\"Missing:\", missing)\n",
    "if unexpected: print(\"Unexpected:\", unexpected)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) FEATURES (match your training: XYZ + Intensity + returns)\n",
    "#    If your model was trained with a different C, we auto-pad/trim.\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    # base features\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    # pad with zeros\n",
    "    pad = np.zeros((X.shape[0], target_C - C), dtype=X.dtype)\n",
    "    return np.concatenate([X, pad], axis=1)\n",
    "\n",
    "# model input channels = mlp1 in_channels\n",
    "C_in = model.mlp1.in_channels\n",
    "print(\"Model expects input features C =\", C_in)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) PREDICT (block by block)\n",
    "# -----------------------------\n",
    "def make_blocks(n_points, npts=4096):\n",
    "    idx = np.arange(n_points)\n",
    "    np.random.shuffle(idx)\n",
    "    blocks = []\n",
    "    for i in range(0, n_points, npts):\n",
    "        b = idx[i:i+npts]\n",
    "        if len(b) < npts:\n",
    "            b = np.pad(b, (0, npts-len(b)), mode=\"wrap\")\n",
    "        blocks.append(b)\n",
    "    return blocks\n",
    "\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = build_features(raw)\n",
    "X_all = fit_C(X_all, C_in)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "blocks = make_blocks(N, NPTS)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "\n",
    "        # simple per-block normalization\n",
    "        xb[:, 0] -= xb[:, 0].mean()\n",
    "        xb[:, 1] -= xb[:, 1].mean()\n",
    "        xb[:, 2] -= xb[:, 2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)  # [1,NPTS,C]\n",
    "        logits = model(xt)                                         # [1,NPTS,num_classes]\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) REAL ACCURACY (GT vs PRED) — SAME POINTS = TRUE ACCURACY\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "# report only main classes (edit if you want more)\n",
    "labels = [1, 2, 3, 6]\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() > 0 else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet)\\n\")\n",
    "for c in [2, 3, 6]:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c24f588-bc4d-46d4-b235-ad51e3c1dd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Checkpoint num_classes: 5\n",
      "✅ Loaded PointNet weights.\n",
      "Model expects input features C = 10\n",
      "Predicting blocks: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 144.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000004_PRED_PT.laz\n",
      "\n",
      "REAL ACCURACY (PointNet)\n",
      "\n",
      "Class 2 Accuracy (Recall): 100.00%\n",
      "Class 3 Accuracy (Recall): 0.00%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 32.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# EDIT THESE PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"D:\\lidarrrrr\\anbu\\dl_models\\pointnet_best.pt\"   # your .pt\n",
    "GT_FILE    = r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000004.laz\"          # classified (ground truth)\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000004.laz\"         # will be created from GT if not exists\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000004_PRED_PT.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) MAKE RAW FROM GT (same points, perfect for real accuracy)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    os.makedirs(os.path.dirname(raw_path), exist_ok=True)\n",
    "    las = laspy.read(gt_path)\n",
    "    print(\"GT classes:\", np.unique(las.classification))\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) BUILD MODEL FROM CHECKPOINT SHAPES (NO GUESSING)\n",
    "# -----------------------------\n",
    "class PointNetFromCkpt(nn.Module):\n",
    "    def __init__(self, sd):\n",
    "        super().__init__()\n",
    "        # Conv1d weights are [out_channels, in_channels, 1]\n",
    "        def conv_from(key):\n",
    "            w = sd[key + \".weight\"]\n",
    "            out_ch, in_ch, k = w.shape\n",
    "            assert k == 1, f\"{key} kernel is not 1, got {k}\"\n",
    "            return nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=True)\n",
    "\n",
    "        self.mlp1 = conv_from(\"mlp1\")\n",
    "        self.mlp2 = conv_from(\"mlp2\")\n",
    "        self.mlp3 = conv_from(\"mlp3\")\n",
    "        self.fc1  = conv_from(\"fc1\")\n",
    "        self.fc2  = conv_from(\"fc2\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.mlp1(x))\n",
    "        x = F.relu(self.mlp2(x))\n",
    "        x = F.relu(self.mlp3(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)          # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1) # [B, N, num_classes]\n",
    "\n",
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "\n",
    "# Your checkpoint keys are: model_state, num_classes, class_weights\n",
    "sd = ckpt[\"model_state\"]\n",
    "num_classes = int(ckpt.get(\"num_classes\", sd[\"fc2.weight\"].shape[0]))\n",
    "print(\"Checkpoint num_classes:\", num_classes)\n",
    "\n",
    "model = PointNetFromCkpt(sd).to(DEVICE)\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(\"✅ Loaded PointNet weights.\")\n",
    "if missing:    print(\"Missing:\", missing)\n",
    "if unexpected: print(\"Unexpected:\", unexpected)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) FEATURES (match your training: XYZ + Intensity + returns)\n",
    "#    If your model was trained with a different C, we auto-pad/trim.\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    # base features\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    # pad with zeros\n",
    "    pad = np.zeros((X.shape[0], target_C - C), dtype=X.dtype)\n",
    "    return np.concatenate([X, pad], axis=1)\n",
    "\n",
    "# model input channels = mlp1 in_channels\n",
    "C_in = model.mlp1.in_channels\n",
    "print(\"Model expects input features C =\", C_in)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) PREDICT (block by block)\n",
    "# -----------------------------\n",
    "def make_blocks(n_points, npts=4096):\n",
    "    idx = np.arange(n_points)\n",
    "    np.random.shuffle(idx)\n",
    "    blocks = []\n",
    "    for i in range(0, n_points, npts):\n",
    "        b = idx[i:i+npts]\n",
    "        if len(b) < npts:\n",
    "            b = np.pad(b, (0, npts-len(b)), mode=\"wrap\")\n",
    "        blocks.append(b)\n",
    "    return blocks\n",
    "\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = build_features(raw)\n",
    "X_all = fit_C(X_all, C_in)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "blocks = make_blocks(N, NPTS)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "\n",
    "        # simple per-block normalization\n",
    "        xb[:, 0] -= xb[:, 0].mean()\n",
    "        xb[:, 1] -= xb[:, 1].mean()\n",
    "        xb[:, 2] -= xb[:, 2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)  # [1,NPTS,C]\n",
    "        logits = model(xt)                                         # [1,NPTS,num_classes]\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) REAL ACCURACY (GT vs PRED) — SAME POINTS = TRUE ACCURACY\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "# report only main classes (edit if you want more)\n",
    "labels = [1, 2, 3, 6]\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() > 0 else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet)\\n\")\n",
    "for c in [2, 3, 6]:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b469aa5-4121-4dec-bbb5-243d0dfcafd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Checkpoint num_classes: 5\n",
      "✅ Loaded PointNet weights.\n",
      "Model expects input features C = 10\n",
      "Predicting blocks: 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000005_PRED_PT.laz\n",
      "\n",
      "REAL ACCURACY (PointNet)\n",
      "\n",
      "Class 2 Accuracy (Recall): 99.96%\n",
      "Class 3 Accuracy (Recall): 0.00%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 35.63%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# EDIT THESE PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"D:\\lidarrrrr\\anbu\\dl_models\\pointnet_best.pt\"   # your .pt\n",
    "GT_FILE    = r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000005.laz\"          # classified (ground truth)\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000005.laz\"         # will be created from GT if not exists\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000005_PRED_PT.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) MAKE RAW FROM GT (same points, perfect for real accuracy)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    os.makedirs(os.path.dirname(raw_path), exist_ok=True)\n",
    "    las = laspy.read(gt_path)\n",
    "    print(\"GT classes:\", np.unique(las.classification))\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) BUILD MODEL FROM CHECKPOINT SHAPES (NO GUESSING)\n",
    "# -----------------------------\n",
    "class PointNetFromCkpt(nn.Module):\n",
    "    def __init__(self, sd):\n",
    "        super().__init__()\n",
    "        # Conv1d weights are [out_channels, in_channels, 1]\n",
    "        def conv_from(key):\n",
    "            w = sd[key + \".weight\"]\n",
    "            out_ch, in_ch, k = w.shape\n",
    "            assert k == 1, f\"{key} kernel is not 1, got {k}\"\n",
    "            return nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=True)\n",
    "\n",
    "        self.mlp1 = conv_from(\"mlp1\")\n",
    "        self.mlp2 = conv_from(\"mlp2\")\n",
    "        self.mlp3 = conv_from(\"mlp3\")\n",
    "        self.fc1  = conv_from(\"fc1\")\n",
    "        self.fc2  = conv_from(\"fc2\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = F.relu(self.mlp1(x))\n",
    "        x = F.relu(self.mlp2(x))\n",
    "        x = F.relu(self.mlp3(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)          # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1) # [B, N, num_classes]\n",
    "\n",
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "\n",
    "# Your checkpoint keys are: model_state, num_classes, class_weights\n",
    "sd = ckpt[\"model_state\"]\n",
    "num_classes = int(ckpt.get(\"num_classes\", sd[\"fc2.weight\"].shape[0]))\n",
    "print(\"Checkpoint num_classes:\", num_classes)\n",
    "\n",
    "model = PointNetFromCkpt(sd).to(DEVICE)\n",
    "missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "print(\"✅ Loaded PointNet weights.\")\n",
    "if missing:    print(\"Missing:\", missing)\n",
    "if unexpected: print(\"Unexpected:\", unexpected)\n",
    "model.eval()\n",
    "\n",
    "# -----------------------------\n",
    "# 3) FEATURES (match your training: XYZ + Intensity + returns)\n",
    "#    If your model was trained with a different C, we auto-pad/trim.\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    # base features\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    # pad with zeros\n",
    "    pad = np.zeros((X.shape[0], target_C - C), dtype=X.dtype)\n",
    "    return np.concatenate([X, pad], axis=1)\n",
    "\n",
    "# model input channels = mlp1 in_channels\n",
    "C_in = model.mlp1.in_channels\n",
    "print(\"Model expects input features C =\", C_in)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) PREDICT (block by block)\n",
    "# -----------------------------\n",
    "def make_blocks(n_points, npts=4096):\n",
    "    idx = np.arange(n_points)\n",
    "    np.random.shuffle(idx)\n",
    "    blocks = []\n",
    "    for i in range(0, n_points, npts):\n",
    "        b = idx[i:i+npts]\n",
    "        if len(b) < npts:\n",
    "            b = np.pad(b, (0, npts-len(b)), mode=\"wrap\")\n",
    "        blocks.append(b)\n",
    "    return blocks\n",
    "\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = build_features(raw)\n",
    "X_all = fit_C(X_all, C_in)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "blocks = make_blocks(N, NPTS)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "\n",
    "        # simple per-block normalization\n",
    "        xb[:, 0] -= xb[:, 0].mean()\n",
    "        xb[:, 1] -= xb[:, 1].mean()\n",
    "        xb[:, 2] -= xb[:, 2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)  # [1,NPTS,C]\n",
    "        logits = model(xt)                                         # [1,NPTS,num_classes]\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) REAL ACCURACY (GT vs PRED) — SAME POINTS = TRUE ACCURACY\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "# report only main classes (edit if you want more)\n",
    "labels = [1, 2, 3, 6]\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() > 0 else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet)\\n\")\n",
    "for c in [2, 3, 6]:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7950914-0b8e-48ab-9666-f20c95712470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique GT Classes:\n",
      "[ 0  1  2  3  4  5 12 14 16 17 19 21 22]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "gt = laspy.read(r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000001.laz\" )\n",
    "\n",
    "cls = np.array(gt.classification)\n",
    "\n",
    "print(\"Unique GT Classes:\")\n",
    "print(np.unique(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47d7834f-5e40-41a5-94b0-276066719942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remap: [1 2 3 6]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "gt = laspy.read(r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000001.laz\" )\n",
    "\n",
    "cls = np.array(gt.classification)\n",
    "\n",
    "# ASPRS → MODEL REMAP\n",
    "remap = {\n",
    "    0:1,\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3,\n",
    "    4:3,\n",
    "    5:6,\n",
    "    12:1,\n",
    "    14:1,\n",
    "    16:1,\n",
    "    17:1,\n",
    "    19:3,\n",
    "    21:3,\n",
    "    22:3\n",
    "}\n",
    "\n",
    "for k,v in remap.items():\n",
    "    cls[cls==k] = v\n",
    "\n",
    "gt.classification = cls\n",
    "gt.write(r\"d:\\lidarrrrr\\anbu\\test\\GT_000001_MODEL.laz\")\n",
    "\n",
    "print(\"After remap:\",np.unique(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1903848-b727-43d1-9584-52b73c5b6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000001_MODEL.laz\")\n",
    "raw.classification[:] = 1\n",
    "raw.write(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000001.laz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0d8e6dc-7f70-4371-bfe5-34aeb2defc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REAL ACCURACY\n",
      "\n",
      "Ground (2): 99.99%\n",
      "Vegetation (3): 0.00%\n",
      "Building (6): 0.00%\n",
      "\n",
      "Overall: 12.26%\n"
     ]
    }
   ],
   "source": [
    "gt   = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000001_MODEL.laz\")\n",
    "pred = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000001_PRED_PT.laz\")\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array(gt.classification)\n",
    "y_pred = np.array(pred.classification)\n",
    "\n",
    "labels = [1,2,3,6]\n",
    "\n",
    "mask = np.isin(y_true,labels)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true[mask],\n",
    "    y_pred[mask],\n",
    "    labels=labels,\n",
    "    digits=4,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_true[mask],y_pred[mask],labels=labels)\n",
    "\n",
    "overall = (np.trace(cm)/np.sum(cm))*100\n",
    "\n",
    "print(\"\\nREAL ACCURACY\\n\")\n",
    "\n",
    "print(f\"Ground (2): {report['2']['recall']*100:.2f}%\")\n",
    "print(f\"Vegetation (3): {report['3']['recall']*100:.2f}%\")\n",
    "print(f\"Building (6): {report['6']['recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nOverall: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0782f70a-daf4-4f3d-8f4c-d85008a5ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REAL ACCURACY\n",
      "\n",
      "Class 1 Accuracy: 0.00%\n",
      "Class 2 Accuracy: 99.99%\n",
      "Class 3 Accuracy: 0.00%\n",
      "Class 6 Accuracy: 0.00%\n",
      "\n",
      "Overall Accuracy: 12.26%\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "gt   = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000001_MODEL.laz\")\n",
    "pred = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000001_PRED_PT.laz\")\n",
    "\n",
    "y_true = np.array(gt.classification)\n",
    "y_pred = np.array(pred.classification)\n",
    "\n",
    "labels = np.unique(y_true)   # auto detect GT classes\n",
    "\n",
    "mask = np.isin(y_true,labels)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true[mask],\n",
    "    y_pred[mask],\n",
    "    labels=labels,\n",
    "    digits=4,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_true[mask],y_pred[mask],labels=labels)\n",
    "\n",
    "overall = (np.trace(cm)/np.sum(cm))*100\n",
    "\n",
    "print(\"\\nREAL ACCURACY\\n\")\n",
    "\n",
    "for c in labels:\n",
    "    if str(c) in report:\n",
    "        print(f\"Class {c} Accuracy: {report[str(c)]['recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4656821f-8c93-44dc-a2ab-91b3c61aaa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remap: [1 2 3 6]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "gt = laspy.read(r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000002.laz\" )\n",
    "\n",
    "cls = np.array(gt.classification)\n",
    "\n",
    "# ASPRS → MODEL REMAP\n",
    "remap = {\n",
    "    0:1,\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3,\n",
    "    4:3,\n",
    "    5:6,\n",
    "    12:1,\n",
    "    14:1,\n",
    "    16:1,\n",
    "    17:1,\n",
    "    19:3,\n",
    "    21:3,\n",
    "    22:3\n",
    "}\n",
    "\n",
    "for k,v in remap.items():\n",
    "    cls[cls==k] = v\n",
    "\n",
    "gt.classification = cls\n",
    "gt.write(r\"d:\\lidarrrrr\\anbu\\test\\GT_000002_MODEL.laz\")\n",
    "\n",
    "print(\"After remap:\",np.unique(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "928a76b1-df4f-47bf-9dd0-863c0c39ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000002_MODEL.laz\")\n",
    "raw.classification[:] = 1\n",
    "raw.write(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000002.laz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02c9c894-9e72-446b-8266-dc95770a73ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REAL ACCURACY\n",
      "\n",
      "Ground (2): 99.99%\n",
      "Vegetation (3): 0.00%\n",
      "Building (6): 0.00%\n",
      "\n",
      "Overall: 9.12%\n"
     ]
    }
   ],
   "source": [
    "gt   = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000002_MODEL.laz\")\n",
    "pred = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000002_PRED_PT.laz\")\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array(gt.classification)\n",
    "y_pred = np.array(pred.classification)\n",
    "\n",
    "labels = [1,2,3,6]\n",
    "\n",
    "mask = np.isin(y_true,labels)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true[mask],\n",
    "    y_pred[mask],\n",
    "    labels=labels,\n",
    "    digits=4,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_true[mask],y_pred[mask],labels=labels)\n",
    "\n",
    "overall = (np.trace(cm)/np.sum(cm))*100\n",
    "\n",
    "print(\"\\nREAL ACCURACY\\n\")\n",
    "\n",
    "print(f\"Ground (2): {report['2']['recall']*100:.2f}%\")\n",
    "print(f\"Vegetation (3): {report['3']['recall']*100:.2f}%\")\n",
    "print(f\"Building (6): {report['6']['recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nOverall: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "174f059d-d1fb-47c8-8e62-9544a744398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REAL ACCURACY\n",
      "\n",
      "Class 1 Accuracy: 0.00%\n",
      "Class 2 Accuracy: 99.99%\n",
      "Class 3 Accuracy: 0.00%\n",
      "Class 6 Accuracy: 0.00%\n",
      "\n",
      "Overall Accuracy: 9.12%\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "gt   = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000002_MODEL.laz\")\n",
    "pred = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000002_PRED_PT.laz\")\n",
    "\n",
    "y_true = np.array(gt.classification)\n",
    "y_pred = np.array(pred.classification)\n",
    "\n",
    "labels = np.unique(y_true)   # auto detect GT classes\n",
    "\n",
    "mask = np.isin(y_true,labels)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true[mask],\n",
    "    y_pred[mask],\n",
    "    labels=labels,\n",
    "    digits=4,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_true[mask],y_pred[mask],labels=labels)\n",
    "\n",
    "overall = (np.trace(cm)/np.sum(cm))*100\n",
    "\n",
    "print(\"\\nREAL ACCURACY\\n\")\n",
    "\n",
    "for c in labels:\n",
    "    if str(c) in report:\n",
    "        print(f\"Class {c} Accuracy: {report[str(c)]['recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8d7c90b-374f-42f2-ae80-8540cf52322c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remap: [1 2 3 6]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "gt = laspy.read(r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000003.laz\" )\n",
    "\n",
    "cls = np.array(gt.classification)\n",
    "\n",
    "# ASPRS → MODEL REMAP\n",
    "remap = {\n",
    "    0:1,\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3,\n",
    "    4:3,\n",
    "    5:6,\n",
    "    12:1,\n",
    "    14:1,\n",
    "    16:1,\n",
    "    17:1,\n",
    "    19:3,\n",
    "    21:3,\n",
    "    22:3\n",
    "}\n",
    "\n",
    "for k,v in remap.items():\n",
    "    cls[cls==k] = v\n",
    "\n",
    "gt.classification = cls\n",
    "gt.write(r\"d:\\lidarrrrr\\anbu\\test\\GT_000003_MODEL.laz\")\n",
    "\n",
    "print(\"After remap:\",np.unique(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3409df43-477e-4807-9a9c-2830c0946dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000003_MODEL.laz\")\n",
    "raw.classification[:] = 1\n",
    "raw.write(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000003.laz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "814cf1a6-0695-4fbe-922f-130dd3ee99b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REAL ACCURACY\n",
      "\n",
      "Class 1 Accuracy: 0.00%\n",
      "Class 2 Accuracy: 99.89%\n",
      "Class 3 Accuracy: 0.03%\n",
      "Class 6 Accuracy: 0.00%\n",
      "\n",
      "Overall Accuracy: 14.79%\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "gt   = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000003_MODEL.laz\")\n",
    "pred = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000003_PRED_PT.laz\")\n",
    "\n",
    "y_true = np.array(gt.classification)\n",
    "y_pred = np.array(pred.classification)\n",
    "\n",
    "labels = np.unique(y_true)   # auto detect GT classes\n",
    "\n",
    "mask = np.isin(y_true,labels)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true[mask],\n",
    "    y_pred[mask],\n",
    "    labels=labels,\n",
    "    digits=4,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_true[mask],y_pred[mask],labels=labels)\n",
    "\n",
    "overall = (np.trace(cm)/np.sum(cm))*100\n",
    "\n",
    "print(\"\\nREAL ACCURACY\\n\")\n",
    "\n",
    "for c in labels:\n",
    "    if str(c) in report:\n",
    "        print(f\"Class {c} Accuracy: {report[str(c)]['recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "add77ca1-6b1c-4d0f-8462-6235154f7941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remap: [1 2 3 6]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "gt = laspy.read(r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000004.laz\" )\n",
    "\n",
    "cls = np.array(gt.classification)\n",
    "\n",
    "# ASPRS → MODEL REMAP\n",
    "remap = {\n",
    "    0:1,\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3,\n",
    "    4:3,\n",
    "    5:6,\n",
    "    12:1,\n",
    "    14:1,\n",
    "    16:1,\n",
    "    17:1,\n",
    "    19:3,\n",
    "    21:3,\n",
    "    22:3\n",
    "}\n",
    "\n",
    "for k,v in remap.items():\n",
    "    cls[cls==k] = v\n",
    "\n",
    "gt.classification = cls\n",
    "gt.write(r\"d:\\lidarrrrr\\anbu\\test\\GT_000004_MODEL.laz\")\n",
    "\n",
    "print(\"After remap:\",np.unique(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f9aeee9-9cf0-40e5-b24a-02ea304c5bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000004_MODEL.laz\")\n",
    "raw.classification[:] = 1\n",
    "raw.write(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000004.laz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3681c1fd-b26a-42cf-9386-80119fbd7730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REAL ACCURACY\n",
      "\n",
      "Class 1 Accuracy: 0.00%\n",
      "Class 2 Accuracy: 100.00%\n",
      "Class 3 Accuracy: 0.03%\n",
      "Class 6 Accuracy: 0.00%\n",
      "\n",
      "Overall Accuracy: 13.30%\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "gt   = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000004_MODEL.laz\")\n",
    "pred = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000004_PRED_PT.laz\")\n",
    "\n",
    "y_true = np.array(gt.classification)\n",
    "y_pred = np.array(pred.classification)\n",
    "\n",
    "labels = np.unique(y_true)   # auto detect GT classes\n",
    "\n",
    "mask = np.isin(y_true,labels)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true[mask],\n",
    "    y_pred[mask],\n",
    "    labels=labels,\n",
    "    digits=4,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_true[mask],y_pred[mask],labels=labels)\n",
    "\n",
    "overall = (np.trace(cm)/np.sum(cm))*100\n",
    "\n",
    "print(\"\\nREAL ACCURACY\\n\")\n",
    "\n",
    "for c in labels:\n",
    "    if str(c) in report:\n",
    "        print(f\"Class {c} Accuracy: {report[str(c)]['recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7599abf6-d7d2-4672-97c2-5410ba445f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remap: [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "gt = laspy.read(r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000005.laz\" )\n",
    "\n",
    "cls = np.array(gt.classification)\n",
    "\n",
    "# ASPRS → MODEL REMAP\n",
    "remap = {\n",
    "    0:1,\n",
    "    1:1,\n",
    "    2:2,\n",
    "    3:3,\n",
    "    4:3,\n",
    "    5:6,\n",
    "    12:1,\n",
    "    14:1,\n",
    "    16:1,\n",
    "    17:1,\n",
    "    19:3,\n",
    "    21:3,\n",
    "    22:3\n",
    "}\n",
    "\n",
    "for k,v in remap.items():\n",
    "    cls[cls==k] = v\n",
    "\n",
    "gt.classification = cls\n",
    "gt.write(r\"d:\\lidarrrrr\\anbu\\test\\GT_000005_MODEL.laz\")\n",
    "\n",
    "print(\"After remap:\",np.unique(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3807338f-35a8-402d-adc3-8004077aedab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000005_MODEL.laz\")\n",
    "raw.classification[:] = 1\n",
    "raw.write(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000005.laz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ce8872a-54af-4be6-b5ee-252be6c49ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "REAL ACCURACY\n",
      "\n",
      "Class 1 Accuracy: 0.01%\n",
      "Class 2 Accuracy: 99.96%\n",
      "Class 3 Accuracy: 0.00%\n",
      "\n",
      "Overall Accuracy: 13.43%\n"
     ]
    }
   ],
   "source": [
    "import laspy\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "gt   = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\GT_000005_MODEL.laz\")\n",
    "pred = laspy.read(r\"d:\\lidarrrrr\\anbu\\test\\RAW_000005_PRED_PT.laz\")\n",
    "\n",
    "y_true = np.array(gt.classification)\n",
    "y_pred = np.array(pred.classification)\n",
    "\n",
    "labels = np.unique(y_true)   # auto detect GT classes\n",
    "\n",
    "mask = np.isin(y_true,labels)\n",
    "\n",
    "report = classification_report(\n",
    "    y_true[mask],\n",
    "    y_pred[mask],\n",
    "    labels=labels,\n",
    "    digits=4,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(y_true[mask],y_pred[mask],labels=labels)\n",
    "\n",
    "overall = (np.trace(cm)/np.sum(cm))*100\n",
    "\n",
    "print(\"\\nREAL ACCURACY\\n\")\n",
    "\n",
    "for c in labels:\n",
    "    if str(c) in report:\n",
    "        print(f\"Class {c} Accuracy: {report[str(c)]['recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c1942-a8c9-4a16-a8e7-78ade68ebacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lidar)",
   "language": "python",
   "name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
