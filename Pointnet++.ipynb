{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb9ea5bd-8d54-420c-ae3f-5a6abfccb11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After remap: [1 2 3 6]\n",
      "Counts: {np.int32(1): np.int64(581375), np.int32(2): np.int64(186001), np.int32(3): np.int64(665955), np.int32(6): np.int64(84601)}\n"
     ]
    }
   ],
   "source": [
    "import laspy, numpy as np\n",
    "\n",
    "IN_GT  = r\"D:\\lidarrrrr\\anbu\\OUTPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000001.laz\"\n",
    "OUT_GT = r\"d:\\lidarrrrr\\anbu\\test\\GT_000001_MODEL.laz\"\n",
    "\n",
    "gt = laspy.read(IN_GT)\n",
    "cls = np.array(gt.classification, dtype=np.int32)\n",
    "\n",
    "REMAP = {\n",
    "    0: 1,\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 3,\n",
    "    4: 3,\n",
    "    5: 6,   # ✅ IMPORTANT: Class 5 -> Building (6)\n",
    "    6: 6,\n",
    "    7: 1,\n",
    "    9: 1,\n",
    "    10: 1,\n",
    "    12: 1,\n",
    "    13: 1,\n",
    "    14: 1,\n",
    "    16: 1,\n",
    "    17: 1,\n",
    "    18: 6,\n",
    "    19: 3,\n",
    "    20: 3,\n",
    "    21: 3,\n",
    "    22: 3,\n",
    "}\n",
    "\n",
    "for k, v in REMAP.items():\n",
    "    cls[cls == k] = v\n",
    "\n",
    "gt.classification = cls.astype(np.uint8)\n",
    "gt.write(OUT_GT)\n",
    "\n",
    "print(\"After remap:\", np.unique(cls))\n",
    "print(\"Counts:\", dict(zip(*np.unique(cls, return_counts=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8ab761-2f7c-4043-b909-38bd44f5cecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'collections.OrderedDict'>\n",
      "Keys: odict_keys(['mlp1.0.weight', 'mlp1.0.bias', 'mlp1.1.weight', 'mlp1.1.bias', 'mlp1.1.running_mean', 'mlp1.1.running_var', 'mlp1.1.num_batches_tracked', 'mlp1.3.weight', 'mlp1.3.bias', 'mlp1.4.weight', 'mlp1.4.bias', 'mlp1.4.running_mean', 'mlp1.4.running_var', 'mlp1.4.num_batches_tracked', 'mlp2.0.weight', 'mlp2.0.bias', 'mlp2.1.weight', 'mlp2.1.bias', 'mlp2.1.running_mean', 'mlp2.1.running_var', 'mlp2.1.num_batches_tracked', 'head.0.weight', 'head.0.bias', 'head.1.weight', 'head.1.bias', 'head.1.running_mean', 'head.1.running_var', 'head.1.num_batches_tracked', 'head.3.weight', 'head.3.bias'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "MODEL_PATH = r\"d:\\lidarrrrr\\anbu\\dl_models\\pointnetpp_best.pt\"\n",
    "ckpt = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "\n",
    "print(\"Type:\", type(ckpt))\n",
    "\n",
    "if isinstance(ckpt, dict):\n",
    "    print(\"Keys:\", ckpt.keys())\n",
    "    if \"model_state\" in ckpt:\n",
    "        sd = ckpt[\"model_state\"]\n",
    "        print(\"\\nFirst 50 layer names:\")\n",
    "        for i, k in enumerate(sd.keys()):\n",
    "            print(k)\n",
    "            if i >= 49:\n",
    "                break\n",
    "        # also show a few shapes (super useful)\n",
    "        print(\"\\nSome shapes:\")\n",
    "        shown = 0\n",
    "        for k, v in sd.items():\n",
    "            if hasattr(v, \"shape\"):\n",
    "                print(k, tuple(v.shape))\n",
    "                shown += 1\n",
    "            if shown >= 15:\n",
    "                break\n",
    "else:\n",
    "    # could be a full model\n",
    "    print(\"This .pt seems to contain a full model object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307b0888-878a-4412-9621-8d10a820e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Loaded state_dict keys: 30\n",
      "Model expects C = 10 | num_classes = 5\n",
      "✅ Model loaded OK\n",
      "Predicting blocks: 371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 371/371 [00:01<00:00, 225.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000001_PRED_PNPP.laz\n",
      "\n",
      "REAL ACCURACY (PointNet++-pt)\n",
      "\n",
      "Class 1 Accuracy (Recall): 35.76%\n",
      "Class 2 Accuracy (Recall): 1.27%\n",
      "Class 3 Accuracy (Recall): 0.00%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 33.36%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"d:\\lidarrrrr\\anbu\\dl_models\\pointnetpp_best.pt\"\n",
    "GT_FILE    = r\"d:\\lidarrrrr\\anbu\\test\\GT_000001_MODEL.laz\"\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000001.laz\"\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000001_PRED_PNPP.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# Make RAW from GT (same points)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    las = laspy.read(gt_path)\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# Load checkpoint (OrderedDict)\n",
    "# -----------------------------\n",
    "sd = torch.load(MODEL_PATH, map_location=\"cpu\")  # OrderedDict\n",
    "assert isinstance(sd, dict), \"Expected state_dict (OrderedDict/dict).\"\n",
    "print(\"Loaded state_dict keys:\", len(sd))\n",
    "\n",
    "# Infer in/out channels from weights\n",
    "# Conv1d weights are [out_ch, in_ch, 1]\n",
    "w_mlp1_0 = sd[\"mlp1.0.weight\"]\n",
    "OUT1, IN_C, K = w_mlp1_0.shape\n",
    "assert K == 1\n",
    "\n",
    "w_head_3 = sd[\"head.3.weight\"]\n",
    "NUM_CLASSES = w_head_3.shape[0]\n",
    "print(\"Model expects C =\", IN_C, \"| num_classes =\", NUM_CLASSES)\n",
    "\n",
    "# -----------------------------\n",
    "# Define model matching keys\n",
    "# -----------------------------\n",
    "class PNPP_Like(nn.Module):\n",
    "    def __init__(self, in_c, num_classes):\n",
    "        super().__init__()\n",
    "        # mlp1: Conv-BN-ReLU-Conv-BN-ReLU\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(in_c, OUT1, 1, bias=True),        # mlp1.0\n",
    "            nn.BatchNorm1d(OUT1),                       # mlp1.1\n",
    "            nn.ReLU(inplace=True),                      # mlp1.2 (not in sd)\n",
    "            nn.Conv1d(OUT1, sd[\"mlp1.3.weight\"].shape[0], 1, bias=True),  # mlp1.3\n",
    "            nn.BatchNorm1d(sd[\"mlp1.3.weight\"].shape[0]),                 # mlp1.4\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # mlp2: Conv-BN-ReLU\n",
    "        out_mlp2 = sd[\"mlp2.0.weight\"].shape[0]\n",
    "        in_mlp2  = sd[\"mlp2.0.weight\"].shape[1]\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(in_mlp2, out_mlp2, 1, bias=True),  # mlp2.0\n",
    "            nn.BatchNorm1d(out_mlp2),                    # mlp2.1\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # head: Conv-BN-ReLU-Conv\n",
    "        out_h0 = sd[\"head.0.weight\"].shape[0]\n",
    "        in_h0  = sd[\"head.0.weight\"].shape[1]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv1d(in_h0, out_h0, 1, bias=True),      # head.0\n",
    "            nn.BatchNorm1d(out_h0),                      # head.1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(sd[\"head.3.weight\"].shape[1], num_classes, 1, bias=True),  # head.3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.head(x)            # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1)   # [B, N, num_classes]\n",
    "\n",
    "model = PNPP_Like(IN_C, NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(sd, strict=True)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded OK\")\n",
    "\n",
    "# -----------------------------\n",
    "# Feature builder (auto fit to C)\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    return np.hstack([X, np.zeros((X.shape[0], target_C - C), dtype=X.dtype)])\n",
    "\n",
    "# -----------------------------\n",
    "# Predict block-by-block\n",
    "# -----------------------------\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = fit_C(build_features(raw), IN_C)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "blocks = []\n",
    "for i in range(0, N, NPTS):\n",
    "    b = idx[i:i+NPTS]\n",
    "    if len(b) < NPTS:\n",
    "        b = np.pad(b, (0, NPTS-len(b)), mode=\"wrap\")\n",
    "    blocks.append(b)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "        xb[:,0] -= xb[:,0].mean()\n",
    "        xb[:,1] -= xb[:,1].mean()\n",
    "        xb[:,2] -= xb[:,2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)\n",
    "        logits = model(xt)\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# REAL Accuracy (GT vs PRED)\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "labels = np.unique(y_true)  # only classes present in GT\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet++-pt)\\n\")\n",
    "for c in labels:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf6f7359-c3ad-4f15-8009-1ff029940d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Loaded state_dict keys: 30\n",
      "Model expects C = 10 | num_classes = 5\n",
      "✅ Model loaded OK\n",
      "Predicting blocks: 853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 853/853 [00:01<00:00, 447.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000002_PRED_PNPP.laz\n",
      "\n",
      "REAL ACCURACY (PointNet++-pt)\n",
      "\n",
      "Class 1 Accuracy (Recall): 63.93%\n",
      "Class 2 Accuracy (Recall): 0.00%\n",
      "Class 3 Accuracy (Recall): 0.00%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 18.27%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"d:\\lidarrrrr\\anbu\\dl_models\\pointnetpp_best.pt\"\n",
    "GT_FILE    = r\"d:\\lidarrrrr\\anbu\\test\\GT_000002_MODEL.laz\"\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000002.laz\"\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000002_PRED_PNPP.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# Make RAW from GT (same points)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    las = laspy.read(gt_path)\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# Load checkpoint (OrderedDict)\n",
    "# -----------------------------\n",
    "sd = torch.load(MODEL_PATH, map_location=\"cpu\")  # OrderedDict\n",
    "assert isinstance(sd, dict), \"Expected state_dict (OrderedDict/dict).\"\n",
    "print(\"Loaded state_dict keys:\", len(sd))\n",
    "\n",
    "# Infer in/out channels from weights\n",
    "# Conv1d weights are [out_ch, in_ch, 1]\n",
    "w_mlp1_0 = sd[\"mlp1.0.weight\"]\n",
    "OUT1, IN_C, K = w_mlp1_0.shape\n",
    "assert K == 1\n",
    "\n",
    "w_head_3 = sd[\"head.3.weight\"]\n",
    "NUM_CLASSES = w_head_3.shape[0]\n",
    "print(\"Model expects C =\", IN_C, \"| num_classes =\", NUM_CLASSES)\n",
    "\n",
    "# -----------------------------\n",
    "# Define model matching keys\n",
    "# -----------------------------\n",
    "class PNPP_Like(nn.Module):\n",
    "    def __init__(self, in_c, num_classes):\n",
    "        super().__init__()\n",
    "        # mlp1: Conv-BN-ReLU-Conv-BN-ReLU\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(in_c, OUT1, 1, bias=True),        # mlp1.0\n",
    "            nn.BatchNorm1d(OUT1),                       # mlp1.1\n",
    "            nn.ReLU(inplace=True),                      # mlp1.2 (not in sd)\n",
    "            nn.Conv1d(OUT1, sd[\"mlp1.3.weight\"].shape[0], 1, bias=True),  # mlp1.3\n",
    "            nn.BatchNorm1d(sd[\"mlp1.3.weight\"].shape[0]),                 # mlp1.4\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # mlp2: Conv-BN-ReLU\n",
    "        out_mlp2 = sd[\"mlp2.0.weight\"].shape[0]\n",
    "        in_mlp2  = sd[\"mlp2.0.weight\"].shape[1]\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(in_mlp2, out_mlp2, 1, bias=True),  # mlp2.0\n",
    "            nn.BatchNorm1d(out_mlp2),                    # mlp2.1\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # head: Conv-BN-ReLU-Conv\n",
    "        out_h0 = sd[\"head.0.weight\"].shape[0]\n",
    "        in_h0  = sd[\"head.0.weight\"].shape[1]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv1d(in_h0, out_h0, 1, bias=True),      # head.0\n",
    "            nn.BatchNorm1d(out_h0),                      # head.1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(sd[\"head.3.weight\"].shape[1], num_classes, 1, bias=True),  # head.3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.head(x)            # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1)   # [B, N, num_classes]\n",
    "\n",
    "model = PNPP_Like(IN_C, NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(sd, strict=True)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded OK\")\n",
    "\n",
    "# -----------------------------\n",
    "# Feature builder (auto fit to C)\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    return np.hstack([X, np.zeros((X.shape[0], target_C - C), dtype=X.dtype)])\n",
    "\n",
    "# -----------------------------\n",
    "# Predict block-by-block\n",
    "# -----------------------------\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = fit_C(build_features(raw), IN_C)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "blocks = []\n",
    "for i in range(0, N, NPTS):\n",
    "    b = idx[i:i+NPTS]\n",
    "    if len(b) < NPTS:\n",
    "        b = np.pad(b, (0, NPTS-len(b)), mode=\"wrap\")\n",
    "    blocks.append(b)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "        xb[:,0] -= xb[:,0].mean()\n",
    "        xb[:,1] -= xb[:,1].mean()\n",
    "        xb[:,2] -= xb[:,2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)\n",
    "        logits = model(xt)\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# REAL Accuracy (GT vs PRED)\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "labels = np.unique(y_true)  # only classes present in GT\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet++-pt)\\n\")\n",
    "for c in labels:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa7979d9-f8fc-450d-be43-561b4f57abf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Loaded state_dict keys: 30\n",
      "Model expects C = 10 | num_classes = 5\n",
      "✅ Model loaded OK\n",
      "Predicting blocks: 552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 552/552 [00:01<00:00, 460.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000003_PRED_PNPP.laz\n",
      "\n",
      "REAL ACCURACY (PointNet++-pt)\n",
      "\n",
      "Class 1 Accuracy (Recall): 43.13%\n",
      "Class 2 Accuracy (Recall): 1.70%\n",
      "Class 3 Accuracy (Recall): 0.00%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 14.40%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"d:\\lidarrrrr\\anbu\\dl_models\\pointnetpp_best.pt\"\n",
    "GT_FILE    = r\"d:\\lidarrrrr\\anbu\\test\\GT_000003_MODEL.laz\"\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000003.laz\"\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000003_PRED_PNPP.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# Make RAW from GT (same points)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    las = laspy.read(gt_path)\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# Load checkpoint (OrderedDict)\n",
    "# -----------------------------\n",
    "sd = torch.load(MODEL_PATH, map_location=\"cpu\")  # OrderedDict\n",
    "assert isinstance(sd, dict), \"Expected state_dict (OrderedDict/dict).\"\n",
    "print(\"Loaded state_dict keys:\", len(sd))\n",
    "\n",
    "# Infer in/out channels from weights\n",
    "# Conv1d weights are [out_ch, in_ch, 1]\n",
    "w_mlp1_0 = sd[\"mlp1.0.weight\"]\n",
    "OUT1, IN_C, K = w_mlp1_0.shape\n",
    "assert K == 1\n",
    "\n",
    "w_head_3 = sd[\"head.3.weight\"]\n",
    "NUM_CLASSES = w_head_3.shape[0]\n",
    "print(\"Model expects C =\", IN_C, \"| num_classes =\", NUM_CLASSES)\n",
    "\n",
    "# -----------------------------\n",
    "# Define model matching keys\n",
    "# -----------------------------\n",
    "class PNPP_Like(nn.Module):\n",
    "    def __init__(self, in_c, num_classes):\n",
    "        super().__init__()\n",
    "        # mlp1: Conv-BN-ReLU-Conv-BN-ReLU\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(in_c, OUT1, 1, bias=True),        # mlp1.0\n",
    "            nn.BatchNorm1d(OUT1),                       # mlp1.1\n",
    "            nn.ReLU(inplace=True),                      # mlp1.2 (not in sd)\n",
    "            nn.Conv1d(OUT1, sd[\"mlp1.3.weight\"].shape[0], 1, bias=True),  # mlp1.3\n",
    "            nn.BatchNorm1d(sd[\"mlp1.3.weight\"].shape[0]),                 # mlp1.4\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # mlp2: Conv-BN-ReLU\n",
    "        out_mlp2 = sd[\"mlp2.0.weight\"].shape[0]\n",
    "        in_mlp2  = sd[\"mlp2.0.weight\"].shape[1]\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(in_mlp2, out_mlp2, 1, bias=True),  # mlp2.0\n",
    "            nn.BatchNorm1d(out_mlp2),                    # mlp2.1\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # head: Conv-BN-ReLU-Conv\n",
    "        out_h0 = sd[\"head.0.weight\"].shape[0]\n",
    "        in_h0  = sd[\"head.0.weight\"].shape[1]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv1d(in_h0, out_h0, 1, bias=True),      # head.0\n",
    "            nn.BatchNorm1d(out_h0),                      # head.1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(sd[\"head.3.weight\"].shape[1], num_classes, 1, bias=True),  # head.3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.head(x)            # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1)   # [B, N, num_classes]\n",
    "\n",
    "model = PNPP_Like(IN_C, NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(sd, strict=True)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded OK\")\n",
    "\n",
    "# -----------------------------\n",
    "# Feature builder (auto fit to C)\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    return np.hstack([X, np.zeros((X.shape[0], target_C - C), dtype=X.dtype)])\n",
    "\n",
    "# -----------------------------\n",
    "# Predict block-by-block\n",
    "# -----------------------------\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = fit_C(build_features(raw), IN_C)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "blocks = []\n",
    "for i in range(0, N, NPTS):\n",
    "    b = idx[i:i+NPTS]\n",
    "    if len(b) < NPTS:\n",
    "        b = np.pad(b, (0, NPTS-len(b)), mode=\"wrap\")\n",
    "    blocks.append(b)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "        xb[:,0] -= xb[:,0].mean()\n",
    "        xb[:,1] -= xb[:,1].mean()\n",
    "        xb[:,2] -= xb[:,2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)\n",
    "        logits = model(xt)\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# REAL Accuracy (GT vs PRED)\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "labels = np.unique(y_true)  # only classes present in GT\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet++-pt)\\n\")\n",
    "for c in labels:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181d53fa-1c91-4b0c-b2ca-10be8a5a714b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Loaded state_dict keys: 30\n",
      "Model expects C = 10 | num_classes = 5\n",
      "✅ Model loaded OK\n",
      "Predicting blocks: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:00<00:00, 159.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000004_PRED_PNPP.laz\n",
      "\n",
      "REAL ACCURACY (PointNet++-pt)\n",
      "\n",
      "Class 1 Accuracy (Recall): 66.37%\n",
      "Class 2 Accuracy (Recall): 0.00%\n",
      "Class 3 Accuracy (Recall): 0.00%\n",
      "Class 6 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 47.96%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"d:\\lidarrrrr\\anbu\\dl_models\\pointnetpp_best.pt\"\n",
    "GT_FILE    = r\"d:\\lidarrrrr\\anbu\\test\\GT_000004_MODEL.laz\"\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000004.laz\"\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000004_PRED_PNPP.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# Make RAW from GT (same points)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    las = laspy.read(gt_path)\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# Load checkpoint (OrderedDict)\n",
    "# -----------------------------\n",
    "sd = torch.load(MODEL_PATH, map_location=\"cpu\")  # OrderedDict\n",
    "assert isinstance(sd, dict), \"Expected state_dict (OrderedDict/dict).\"\n",
    "print(\"Loaded state_dict keys:\", len(sd))\n",
    "\n",
    "# Infer in/out channels from weights\n",
    "# Conv1d weights are [out_ch, in_ch, 1]\n",
    "w_mlp1_0 = sd[\"mlp1.0.weight\"]\n",
    "OUT1, IN_C, K = w_mlp1_0.shape\n",
    "assert K == 1\n",
    "\n",
    "w_head_3 = sd[\"head.3.weight\"]\n",
    "NUM_CLASSES = w_head_3.shape[0]\n",
    "print(\"Model expects C =\", IN_C, \"| num_classes =\", NUM_CLASSES)\n",
    "\n",
    "# -----------------------------\n",
    "# Define model matching keys\n",
    "# -----------------------------\n",
    "class PNPP_Like(nn.Module):\n",
    "    def __init__(self, in_c, num_classes):\n",
    "        super().__init__()\n",
    "        # mlp1: Conv-BN-ReLU-Conv-BN-ReLU\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(in_c, OUT1, 1, bias=True),        # mlp1.0\n",
    "            nn.BatchNorm1d(OUT1),                       # mlp1.1\n",
    "            nn.ReLU(inplace=True),                      # mlp1.2 (not in sd)\n",
    "            nn.Conv1d(OUT1, sd[\"mlp1.3.weight\"].shape[0], 1, bias=True),  # mlp1.3\n",
    "            nn.BatchNorm1d(sd[\"mlp1.3.weight\"].shape[0]),                 # mlp1.4\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # mlp2: Conv-BN-ReLU\n",
    "        out_mlp2 = sd[\"mlp2.0.weight\"].shape[0]\n",
    "        in_mlp2  = sd[\"mlp2.0.weight\"].shape[1]\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(in_mlp2, out_mlp2, 1, bias=True),  # mlp2.0\n",
    "            nn.BatchNorm1d(out_mlp2),                    # mlp2.1\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # head: Conv-BN-ReLU-Conv\n",
    "        out_h0 = sd[\"head.0.weight\"].shape[0]\n",
    "        in_h0  = sd[\"head.0.weight\"].shape[1]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv1d(in_h0, out_h0, 1, bias=True),      # head.0\n",
    "            nn.BatchNorm1d(out_h0),                      # head.1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(sd[\"head.3.weight\"].shape[1], num_classes, 1, bias=True),  # head.3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.head(x)            # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1)   # [B, N, num_classes]\n",
    "\n",
    "model = PNPP_Like(IN_C, NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(sd, strict=True)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded OK\")\n",
    "\n",
    "# -----------------------------\n",
    "# Feature builder (auto fit to C)\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    return np.hstack([X, np.zeros((X.shape[0], target_C - C), dtype=X.dtype)])\n",
    "\n",
    "# -----------------------------\n",
    "# Predict block-by-block\n",
    "# -----------------------------\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = fit_C(build_features(raw), IN_C)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "blocks = []\n",
    "for i in range(0, N, NPTS):\n",
    "    b = idx[i:i+NPTS]\n",
    "    if len(b) < NPTS:\n",
    "        b = np.pad(b, (0, NPTS-len(b)), mode=\"wrap\")\n",
    "    blocks.append(b)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "        xb[:,0] -= xb[:,0].mean()\n",
    "        xb[:,1] -= xb[:,1].mean()\n",
    "        xb[:,2] -= xb[:,2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)\n",
    "        logits = model(xt)\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# REAL Accuracy (GT vs PRED)\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "labels = np.unique(y_true)  # only classes present in GT\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet++-pt)\\n\")\n",
    "for c in labels:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd99b083-1d08-49ee-a27e-f7978a98a4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 3050\n",
      "Loaded state_dict keys: 30\n",
      "Model expects C = 10 | num_classes = 5\n",
      "✅ Model loaded OK\n",
      "Predicting blocks: 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:01<00:00, 408.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: d:\\lidarrrrr\\anbu\\test\\RAW_000005_PRED_PNPP.laz\n",
      "\n",
      "REAL ACCURACY (PointNet++-pt)\n",
      "\n",
      "Class 1 Accuracy (Recall): 60.52%\n",
      "Class 2 Accuracy (Recall): 0.73%\n",
      "Class 3 Accuracy (Recall): 0.00%\n",
      "\n",
      "Overall Accuracy: 22.55%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import laspy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# PATHS\n",
    "# -----------------------------\n",
    "MODEL_PATH = r\"d:\\lidarrrrr\\anbu\\dl_models\\pointnetpp_best.pt\"\n",
    "GT_FILE    = r\"d:\\lidarrrrr\\anbu\\test\\GT_000005_MODEL.laz\"\n",
    "RAW_FILE   = r\"D:\\lidarrrrr\\anbu\\INPUT FILE\\DX3013595 PASQUILIO\\LAZ\\DX3013595 PASQUILIO000005.laz\"\n",
    "PRED_FILE  = r\"d:\\lidarrrrr\\anbu\\test\\RAW_000005_PRED_PNPP.laz\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# -----------------------------\n",
    "# Make RAW from GT (same points)\n",
    "# -----------------------------\n",
    "def make_raw_from_gt(gt_path, raw_path):\n",
    "    las = laspy.read(gt_path)\n",
    "    las.classification[:] = 1\n",
    "    las.write(raw_path)\n",
    "    print(\"✅ RAW created:\", raw_path)\n",
    "\n",
    "if not os.path.exists(RAW_FILE):\n",
    "    make_raw_from_gt(GT_FILE, RAW_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# Load checkpoint (OrderedDict)\n",
    "# -----------------------------\n",
    "sd = torch.load(MODEL_PATH, map_location=\"cpu\")  # OrderedDict\n",
    "assert isinstance(sd, dict), \"Expected state_dict (OrderedDict/dict).\"\n",
    "print(\"Loaded state_dict keys:\", len(sd))\n",
    "\n",
    "# Infer in/out channels from weights\n",
    "# Conv1d weights are [out_ch, in_ch, 1]\n",
    "w_mlp1_0 = sd[\"mlp1.0.weight\"]\n",
    "OUT1, IN_C, K = w_mlp1_0.shape\n",
    "assert K == 1\n",
    "\n",
    "w_head_3 = sd[\"head.3.weight\"]\n",
    "NUM_CLASSES = w_head_3.shape[0]\n",
    "print(\"Model expects C =\", IN_C, \"| num_classes =\", NUM_CLASSES)\n",
    "\n",
    "# -----------------------------\n",
    "# Define model matching keys\n",
    "# -----------------------------\n",
    "class PNPP_Like(nn.Module):\n",
    "    def __init__(self, in_c, num_classes):\n",
    "        super().__init__()\n",
    "        # mlp1: Conv-BN-ReLU-Conv-BN-ReLU\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Conv1d(in_c, OUT1, 1, bias=True),        # mlp1.0\n",
    "            nn.BatchNorm1d(OUT1),                       # mlp1.1\n",
    "            nn.ReLU(inplace=True),                      # mlp1.2 (not in sd)\n",
    "            nn.Conv1d(OUT1, sd[\"mlp1.3.weight\"].shape[0], 1, bias=True),  # mlp1.3\n",
    "            nn.BatchNorm1d(sd[\"mlp1.3.weight\"].shape[0]),                 # mlp1.4\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # mlp2: Conv-BN-ReLU\n",
    "        out_mlp2 = sd[\"mlp2.0.weight\"].shape[0]\n",
    "        in_mlp2  = sd[\"mlp2.0.weight\"].shape[1]\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Conv1d(in_mlp2, out_mlp2, 1, bias=True),  # mlp2.0\n",
    "            nn.BatchNorm1d(out_mlp2),                    # mlp2.1\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # head: Conv-BN-ReLU-Conv\n",
    "        out_h0 = sd[\"head.0.weight\"].shape[0]\n",
    "        in_h0  = sd[\"head.0.weight\"].shape[1]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv1d(in_h0, out_h0, 1, bias=True),      # head.0\n",
    "            nn.BatchNorm1d(out_h0),                      # head.1\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(sd[\"head.3.weight\"].shape[1], num_classes, 1, bias=True),  # head.3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, N, C] -> [B, C, N]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = self.head(x)            # [B, num_classes, N]\n",
    "        return x.permute(0, 2, 1)   # [B, N, num_classes]\n",
    "\n",
    "model = PNPP_Like(IN_C, NUM_CLASSES).to(DEVICE)\n",
    "model.load_state_dict(sd, strict=True)\n",
    "model.eval()\n",
    "print(\"✅ Model loaded OK\")\n",
    "\n",
    "# -----------------------------\n",
    "# Feature builder (auto fit to C)\n",
    "# -----------------------------\n",
    "def build_features(las):\n",
    "    dims = set(las.point_format.dimension_names)\n",
    "    xyz = np.vstack([las.x, las.y, las.z]).T.astype(np.float32)\n",
    "\n",
    "    intensity = np.array(las.intensity, dtype=np.float32) if \"intensity\" in dims else np.zeros(len(xyz), np.float32)\n",
    "    rn = np.array(las.return_number, dtype=np.float32) if \"return_number\" in dims else np.ones(len(xyz), np.float32)\n",
    "    nr = np.array(las.number_of_returns, dtype=np.float32) if \"number_of_returns\" in dims else np.ones(len(xyz), np.float32)\n",
    "\n",
    "    if intensity.max() > intensity.min():\n",
    "        intensity = (intensity - intensity.min()) / (intensity.max() - intensity.min() + 1e-6)\n",
    "    ret_ratio = rn / (nr + 1e-6)\n",
    "\n",
    "    X = np.column_stack([xyz, intensity, ret_ratio, nr]).astype(np.float32)  # C=6\n",
    "    return X\n",
    "\n",
    "def fit_C(X, target_C):\n",
    "    C = X.shape[1]\n",
    "    if C == target_C:\n",
    "        return X\n",
    "    if C > target_C:\n",
    "        return X[:, :target_C]\n",
    "    return np.hstack([X, np.zeros((X.shape[0], target_C - C), dtype=X.dtype)])\n",
    "\n",
    "# -----------------------------\n",
    "# Predict block-by-block\n",
    "# -----------------------------\n",
    "raw = laspy.read(RAW_FILE)\n",
    "X_all = fit_C(build_features(raw), IN_C)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "NPTS = 4096\n",
    "\n",
    "idx = np.arange(N)\n",
    "np.random.shuffle(idx)\n",
    "blocks = []\n",
    "for i in range(0, N, NPTS):\n",
    "    b = idx[i:i+NPTS]\n",
    "    if len(b) < NPTS:\n",
    "        b = np.pad(b, (0, NPTS-len(b)), mode=\"wrap\")\n",
    "    blocks.append(b)\n",
    "\n",
    "pred = np.zeros(N, dtype=np.int32)\n",
    "\n",
    "print(\"Predicting blocks:\", len(blocks))\n",
    "with torch.no_grad():\n",
    "    for b in tqdm(blocks):\n",
    "        xb = X_all[b].copy()\n",
    "        xb[:,0] -= xb[:,0].mean()\n",
    "        xb[:,1] -= xb[:,1].mean()\n",
    "        xb[:,2] -= xb[:,2].min()\n",
    "\n",
    "        xt = torch.from_numpy(xb).float().unsqueeze(0).to(DEVICE)\n",
    "        logits = model(xt)\n",
    "        pb = logits.argmax(-1).squeeze(0).cpu().numpy().astype(np.int32)\n",
    "        pred[b] = pb\n",
    "\n",
    "# Save predicted LAZ\n",
    "out = laspy.LasData(header=raw.header)\n",
    "out.points = raw.points\n",
    "out.classification = pred.astype(np.uint8)\n",
    "out.write(PRED_FILE)\n",
    "print(\"✅ Saved:\", PRED_FILE)\n",
    "\n",
    "# -----------------------------\n",
    "# REAL Accuracy (GT vs PRED)\n",
    "# -----------------------------\n",
    "gt = laspy.read(GT_FILE)\n",
    "y_true = np.array(gt.classification, dtype=np.int32)\n",
    "y_pred = pred.astype(np.int32)\n",
    "\n",
    "labels = np.unique(y_true)  # only classes present in GT\n",
    "mask = np.isin(y_true, labels)\n",
    "\n",
    "rep = classification_report(y_true[mask], y_pred[mask], labels=labels, digits=4, zero_division=0, output_dict=True)\n",
    "cm  = confusion_matrix(y_true[mask], y_pred[mask], labels=labels)\n",
    "overall = (np.trace(cm) / np.sum(cm)) * 100.0 if cm.sum() else 0.0\n",
    "\n",
    "print(\"\\nREAL ACCURACY (PointNet++-pt)\\n\")\n",
    "for c in labels:\n",
    "    print(f\"Class {c} Accuracy (Recall): {rep[str(c)]['recall']*100:.2f}%\")\n",
    "print(f\"\\nOverall Accuracy: {overall:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a62b6f-355a-4547-b7cd-70510ea7ccfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lidar)",
   "language": "python",
   "name": "lidar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
